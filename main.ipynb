{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.distributions as distributions\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torchvision\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "\n",
    "data = torchvision.datasets.MNIST(\".\", download=True, train=True)\n",
    "new_data = torchvision.datasets.MNIST(\".\", download=True, train=False, transform=None)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "images = []\n",
    "for i, (image, label) in enumerate(data):\n",
    "    if i > 5000:\n",
    "        break\n",
    "    image_mod = np.array(image) \n",
    "    image_x = 28\n",
    "    image_y = 28\n",
    "    hole_size_x = 10\n",
    "    hole_size_y = 10\n",
    "    x = np.zeros((image_x*image_y,))\n",
    "    y = np.zeros((image_x*image_y,))\n",
    "    z = np.zeros((image_x*image_y,))\n",
    "    counter = 0\n",
    "    for i, row in enumerate(image_mod):\n",
    "        for j, a in enumerate(row):\n",
    "            x[counter] = j\n",
    "            y[counter] = i\n",
    "            z[counter] = a\n",
    "            counter += 1    \n",
    "    imshow(image_mod)\n",
    "    img_center_x = image_x/2\n",
    "    img_center_y = image_y/2\n",
    "    hole_beg_x = img_center_x - hole_size_x/2\n",
    "    hole_end_x = img_center_x + hole_size_x/2\n",
    "    hole_beg_y = img_center_y - hole_size_y/2\n",
    "    hole_end_y = img_center_y + hole_size_y/2\n",
    "    mask = []\n",
    "    #remove center rectangle\n",
    "    for a in range(image_x*image_y):\n",
    "        if not hole_beg_x < x[a] < hole_end_x or not hole_beg_y < y[a] < hole_end_x:\n",
    "                mask.append(a)\n",
    "    x = x[mask]\n",
    "    y = y[mask]\n",
    "    z = z[mask]\n",
    "    # move points to fill hole\n",
    "    x_old = np.copy(x)\n",
    "    y_old = np.copy(y)\n",
    "    for a in range(len(x)):\n",
    "        if hole_beg_x <= x[a] <= hole_end_x or hole_beg_y <= y[a] <= hole_end_x:\n",
    "            if x[a] > y[a] and (image_x - x[a]) > y[a]:\n",
    "                y[a] *= (image_x - hole_size_x) / (image_x - abs(image_x - 2*x[a]))\n",
    "                if np.isinf(y[a]):\n",
    "                    print(a)\n",
    "            elif x[a] < y[a] and (image_x - x[a]) < y[a]:\n",
    "                x[a] *= (image_y - hole_size_y) / (image_y - abs(image_y - 2*y[a]))\n",
    "            elif x[a] > y[a] and (image_x - x[a]) < y[a]:\n",
    "                y[a] = (y[a] - image_y) * ((image_x - hole_size_x) / (image_x - abs(image_x - 2*x[a]))) + image_y\n",
    "                if np.isinf(y[a]):\n",
    "                    print(a)\n",
    "            elif x[a] < y[a] and (image_x - x[a]) > y[a]:\n",
    "                x[a] = (x[a] - image_x) * (image_y - hole_size_y) / (image_y - abs(image_y - 2*y[a])) + image_x\n",
    "    x_new = np.arange(0,28,1)\n",
    "    y_new = np.arange(0,28,1)\n",
    "    x_new, y_new = np.meshgrid(x_new, y_new)\n",
    "    z_new = interpolate.griddata((x, y), z, (x_new, y_new), method='linear')\n",
    "    x_2 = interpolate.griddata((x, y), x_old, (x_new, y_new), method='linear')\n",
    "    y_2 = interpolate.griddata((x, y), y_old, (x_new, y_new), method='linear')\n",
    "    z_new[z_new<0]=0\n",
    "    images.append(torch.from_numpy(np.stack([z_new, x_2, y_2])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "batch_size: int = 20\n",
    "epoch: int = 10\n",
    "lr: float = 0.01\n",
    "test_split: float = 0.2\n",
    "\n",
    "random_seed: int = 10\n",
    "shuffle_dataset: bool = True\n",
    "\n",
    "dataset_size: int = len(images)\n",
    "indices: list = list(range(dataset_size))\n",
    "split: int = int(np.floor(test_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler: SubsetRandomSampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler: SubsetRandomSampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_loader: DataLoader = DataLoader(images, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader: DataLoader = DataLoader(images, batch_size=batch_size, sampler=test_sampler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "k = 3\n",
    "l = 1\n",
    "n = 10*10\n",
    "\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 30, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(30, 60, kernel_size=5)\n",
    "        # self.conv3 = nn.Conv2d(60, 90, kernel_size=5)\n",
    "        self.linear1 = nn.Linear(320*3, 1256)\n",
    "        self.linear2 = nn.Linear(1256, k + k * n + n * l * k + k * n)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = f.relu(f.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "        x = f.relu(f.max_pool2d(self.conv2(x), kernel_size=2))\n",
    "        # x = f.relu(f.max_pool2d(self.conv3(x), kernel_size=2))\n",
    "        x = x.view(-1, 320*3)\n",
    "        x = f.relu(self.linear1(x))\n",
    "        return self.linear2(x)\n",
    "\n",
    "\n",
    "model: Network = Network().double()\n",
    "optimizer = Adam(model.parameters(), lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch 0 completed\n",
      "Epoch 1 completed\n",
      "Epoch 2 completed\n",
      "Epoch 3 completed\n",
      "Epoch 4 completed\n",
      "Epoch 5 completed\n",
      "Epoch 6 completed\n",
      "Epoch 7 completed\n",
      "Epoch 8 completed\n",
      "Epoch 9 completed\n",
      "Epoch 10 completed\n",
      "Epoch 11 completed\n",
      "Epoch 12 completed\n",
      "Epoch 13 completed\n",
      "Epoch 14 completed\n",
      "Epoch 15 completed\n",
      "Epoch 16 completed\n",
      "Epoch 17 completed\n",
      "Epoch 18 completed\n",
      "Epoch 19 completed\n",
      "Epoch 20 completed\n",
      "Epoch 21 completed\n",
      "Epoch 22 completed\n",
      "Epoch 23 completed\n",
      "Epoch 24 completed\n",
      "Epoch 25 completed\n",
      "Epoch 26 completed\n",
      "Epoch 27 completed\n",
      "Epoch 28 completed\n",
      "Epoch 29 completed\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "epoch = 30\n",
    "model = model.to('cpu')\n",
    "def loss_function(x: torch.Tensor, input):\n",
    "    x = x.view((len(input), -1))\n",
    "    sum = torch.tensor(0).double().to(device)\n",
    "    sum.requires_grad = True\n",
    "    for i in range(len(input)):\n",
    "        p:torch.Tensor = x[i][:k]\n",
    "        p_tuple = torch.split(p, 1, 0)\n",
    "        m:torch.Tensor = x[i][k:k+k*n].view(-1, k)\n",
    "        m_tuple = torch.split(m, 1, 1)\n",
    "        A:torch.Tensor = x[i][k+k*n:k+k*n+n*l*k].view(-1, l, k)\n",
    "        A_tuple = torch.split(A, 1, 2)\n",
    "        d:torch.Tensor = x[i][k+k*n+n*l*k:].view(-1,k)\n",
    "        d_tuple = torch.split(d, 1, 1)\n",
    "        dists = []\n",
    "        for p, m, A, d in zip(p_tuple, m_tuple, A_tuple, d_tuple):\n",
    "            dists.append((p, distributions.lowrank_multivariate_normal.LowRankMultivariateNormal(m.view(-1), A.view(n*l, l), torch.abs(d).view(-1))))\n",
    "        for p, dist in dists:\n",
    "            sum.add(-p.log().add(-dist.log_prob(input[i][0][9:19,9:19].contiguous().view(-1))))\n",
    "    return sum\n",
    "\n",
    "for e in range(epoch):\n",
    "    for i, x in enumerate(train_loader):\n",
    "        # x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        result = model(x.double())\n",
    "        loss = loss_function(result, x)\n",
    "        loss.backward()\n",
    "    print(\"Epoch {} completed\".format(e))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[-4.5391],\n         [ 0.0698],\n         [ 2.7748],\n         [-1.6213],\n         [-1.1211],\n         [-6.4719],\n         [-2.3872],\n         [-5.1822],\n         [-5.0768],\n         [-3.7323],\n         [ 7.9998],\n         [-3.8013],\n         [-3.0617],\n         [ 2.2454],\n         [-0.0831],\n         [-1.2211],\n         [-2.0102],\n         [ 1.1770],\n         [ 2.1792],\n         [ 0.0340],\n         [-7.9769],\n         [-0.3310],\n         [-1.5029],\n         [ 5.0349],\n         [-7.2467],\n         [-4.3992],\n         [ 3.3885],\n         [ 1.3320],\n         [-4.0132],\n         [ 0.9017],\n         [-4.3440],\n         [-2.4263],\n         [ 5.3133],\n         [ 0.1555],\n         [-6.6998],\n         [-0.6416],\n         [ 1.1528],\n         [-1.5976],\n         [-9.2596],\n         [-0.9579],\n         [ 5.1827],\n         [-0.0495],\n         [ 4.8090],\n         [-7.9491],\n         [-1.3177],\n         [-3.9665],\n         [-1.5022],\n         [-6.2682],\n         [ 4.2421],\n         [-2.1748],\n         [ 1.2364],\n         [-1.3008],\n         [ 0.2637],\n         [-2.7440],\n         [-2.5476],\n         [-4.3193],\n         [ 3.0790],\n         [ 6.5603],\n         [ 3.3716],\n         [-0.6208],\n         [ 2.0160],\n         [-5.2579],\n         [-2.6088],\n         [ 0.9390],\n         [ 0.1906],\n         [-2.7548],\n         [ 2.0565],\n         [ 3.3063],\n         [-2.4521],\n         [ 2.5811],\n         [ 3.1792],\n         [ 2.3965],\n         [-3.5600],\n         [ 4.2257],\n         [-1.9166],\n         [ 9.3394],\n         [ 3.9218],\n         [-7.3443],\n         [ 3.3756],\n         [ 4.3459],\n         [-2.3101],\n         [ 2.1351],\n         [-7.4984],\n         [ 2.9258],\n         [ 0.9835],\n         [-0.1009],\n         [ 5.9206],\n         [ 2.0697],\n         [ 4.9782],\n         [ 0.7200],\n         [-3.1364],\n         [ 3.2032],\n         [-1.7175],\n         [-6.4175],\n         [-2.9653],\n         [ 3.3969],\n         [ 0.2443],\n         [-2.1867],\n         [-0.9111],\n         [ 4.3194]], dtype=torch.float64, grad_fn=<SplitBackward>),\n tensor([[ -3.3529],\n         [ -9.9382],\n         [ -3.0556],\n         [  2.6359],\n         [  2.8634],\n         [  4.6460],\n         [  0.1123],\n         [ -0.8883],\n         [  6.0585],\n         [  4.1587],\n         [ -6.2565],\n         [ -1.5896],\n         [ -1.1415],\n         [  5.3582],\n         [ -4.2725],\n         [  3.9032],\n         [  2.2244],\n         [ -0.9583],\n         [ -1.7249],\n         [  1.3684],\n         [ -1.0666],\n         [ -0.8076],\n         [ -0.8818],\n         [  2.5635],\n         [  0.4290],\n         [  2.3592],\n         [ -2.2496],\n         [  0.5319],\n         [ -6.7705],\n         [-12.3127],\n         [  0.8957],\n         [  3.8241],\n         [  4.4774],\n         [ -4.1258],\n         [ -3.4779],\n         [ -3.1698],\n         [ -0.0361],\n         [ -3.4901],\n         [  1.8089],\n         [ -5.0107],\n         [  2.3509],\n         [ -2.3032],\n         [ -1.7656],\n         [  0.2166],\n         [ -4.2165],\n         [  1.6766],\n         [  0.9018],\n         [ -2.5250],\n         [ -0.3471],\n         [  3.0318],\n         [ -3.4829],\n         [  0.9119],\n         [  1.5120],\n         [ -0.5024],\n         [  4.9776],\n         [ -5.9561],\n         [ -7.1582],\n         [ -2.4626],\n         [ -2.4738],\n         [  1.5792],\n         [ -1.5005],\n         [ -2.6950],\n         [  1.0515],\n         [  0.6361],\n         [ -2.8066],\n         [  3.7807],\n         [ -0.0372],\n         [ -0.7987],\n         [  1.9488],\n         [ -6.7647],\n         [ -2.7649],\n         [ -4.0558],\n         [ -1.7911],\n         [ -1.5178],\n         [  0.6687],\n         [  4.9037],\n         [  1.1083],\n         [ -3.9941],\n         [  0.5577],\n         [ -1.0810],\n         [ -0.3341],\n         [ -4.2796],\n         [ -3.2089],\n         [ -6.5600],\n         [ -0.8619],\n         [ -6.0125],\n         [ -1.5875],\n         [ -1.9786],\n         [ -1.5128],\n         [ -3.5375],\n         [ -3.0531],\n         [ -3.8416],\n         [  0.9616],\n         [ -1.8784],\n         [  3.7546],\n         [  5.5157],\n         [  4.1978],\n         [  2.0192],\n         [ -0.9699],\n         [ -3.2132]], dtype=torch.float64, grad_fn=<SplitBackward>),\n tensor([[ -3.2023],\n         [  0.7229],\n         [  0.9390],\n         [ -2.5231],\n         [  0.6359],\n         [  0.3786],\n         [ -2.3630],\n         [  3.9763],\n         [  2.6455],\n         [  1.8688],\n         [ -1.2689],\n         [  5.8362],\n         [  1.2270],\n         [ -2.6266],\n         [ -3.9860],\n         [ -3.2413],\n         [  7.1362],\n         [  5.0926],\n         [  1.9479],\n         [ -4.3317],\n         [  1.6460],\n         [ -0.1623],\n         [  3.1616],\n         [ -1.5572],\n         [  3.4125],\n         [ -0.3516],\n         [  1.7338],\n         [  3.8145],\n         [  4.7902],\n         [ -5.5147],\n         [ -0.1537],\n         [  3.8089],\n         [ -4.4661],\n         [  0.0150],\n         [  4.2524],\n         [  3.2246],\n         [ -6.2222],\n         [ -1.4452],\n         [  4.3429],\n         [  3.1215],\n         [  7.3141],\n         [  0.3251],\n         [  6.7888],\n         [  3.4445],\n         [  4.1029],\n         [  6.8461],\n         [ -4.1842],\n         [-10.7138],\n         [  2.2267],\n         [  3.4124],\n         [  1.7567],\n         [ -3.5550],\n         [ -8.0981],\n         [  0.5269],\n         [  4.6950],\n         [ -1.2333],\n         [ -0.4516],\n         [  3.1421],\n         [ -5.6156],\n         [ -0.1963],\n         [  1.0238],\n         [  6.5376],\n         [  0.4278],\n         [  2.1956],\n         [  3.1710],\n         [ -1.4145],\n         [  3.9105],\n         [ -0.3282],\n         [ -3.3322],\n         [ -7.6400],\n         [  4.9823],\n         [ -1.4894],\n         [  1.4245],\n         [ -1.7824],\n         [  1.6348],\n         [  4.6595],\n         [ -0.9719],\n         [ -2.2141],\n         [ -4.1140],\n         [  0.8885],\n         [ -2.3261],\n         [  3.0560],\n         [  0.9025],\n         [ -2.9417],\n         [ -2.4448],\n         [ -4.1181],\n         [ -2.7655],\n         [ -3.9373],\n         [ -4.7373],\n         [  0.3689],\n         [  1.3950],\n         [  0.3269],\n         [ -7.3838],\n         [  4.3045],\n         [  0.7061],\n         [ -3.8893],\n         [ -0.4693],\n         [  2.4106],\n         [ -2.7967],\n         [  1.6325]], dtype=torch.float64, grad_fn=<SplitBackward>))"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 15
    }
   ],
   "source": [
    "model(images[0].unsqueeze(0))[0][k:k+k*n].view(-1, k).split(1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([156.0000,  56.3158, 101.1200, 111.4902,  53.5044,  16.0941,  24.4018,\n         87.0824,   1.6431,   0.0000,   0.0000,   0.0000,  17.1452,  48.5970,\n          0.3949,  13.4965,  52.4713,   0.0000,   0.0000,   0.0000,   0.0000,\n          0.0000,   0.0000,   0.0000,   2.5913,   7.3421,   0.0000,   0.0000,\n          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n          0.0000,   0.0000,   0.0000,   5.6483,  42.3625,  79.0766,  68.3778,\n          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,  11.4201,  57.1007,\n         87.7500, 126.8148, 156.9074,   0.0000,   0.0000,   0.0000,   0.0000,\n         30.1978,  80.3333, 107.1736, 129.5625, 169.3750, 209.1875,   0.0000,\n          0.0000,   2.1238,  19.5000,  96.0909, 154.6667, 168.6667, 189.7500,\n        211.1875, 251.0000], dtype=torch.float64)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 33
    }
   ],
   "source": [
    "images[0][0][9:19,9:19].contiguous().view(-1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}